{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stopwordsiso as stopwords\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "['দেয়', 'র', 'একটি', 'জানতে', 'এমনকী', 'এসে', 'তখন', 'ওঁদের', 'ওর', 'পরে', 'অনেকেই', 'করা', 'এমন', 'দিলেন', 'আপনি', 'দুটো', 'এক্', 'ভাবেই', 'মোট', 'মধ্যেও', 'হওয়া', 'ভাবে', 'যা', 'হইয়া', 'আমার', 'জানিয়েছে', 'এদের', 'ওঁরা', 'তাঁদের', 'নেওয়া', 'গিয়ে', 'পারি', 'বললেন', 'থাকেন', 'প্রথম', 'যায়', 'বলেন', 'গোটা', 'থেকে', 'অবধি', 'যত', 'যারা', 'সম্প্রতি', 'দিতে', 'দ্বারা', 'ই', 'এল', 'নাই', 'তবে', 'তুমি', 'দেওয়ার', 'তত', 'একে', 'যাওয়া', 'তো', 'হিসাবে', 'যতটা', 'তুলে', 'তোমার', 'হচ্ছে', 'ফলে', 'আদ্যভাগে', 'কয়েক', 'বার', 'করে', 'চেষ্টা', 'সুতরাং', 'হয়', 'এমনি', 'আই', 'করেছে', 'তারা', 'হলেও', 'করেছিলেন', 'হন', 'নেই', 'বেশ', 'কবে', 'যাতে', 'সামনে', 'বক্তব্য', 'কে', 'কোনো', 'হত', 'বিভিন্ন', 'হোক', 'এটি', 'হবে', 'সব', 'এখানেই', 'যাদের', 'যেমন', 'বলা', 'উনি', 'করছেন', 'হল', 'বলতে', 'বিনা', 'যথেষ্ট', 'আমাদের', 'এতে', 'কারণ', 'এঁদের', 'পারেন', 'নিজের', 'সাধারণ', 'ঐ', 'হয়েছে', 'গুলি', 'কি', 'নিয়ে', 'ধামার', 'রেখে', 'হলে', 'একবার', 'যান', 'পেয়্র্', 'তাও', 'কাছে', 'হইবে', 'ব্যাপারে', 'আবার', 'তাঁর', 'দেখা', 'পেয়ে', 'সবার', 'নয়', 'তথা', 'করিয়ে', 'একই', 'দেখে', 'হবেন', 'নাগাদ', 'যাওয়া', 'হলো', 'সেটা', 'এখনও', 'করবেন', 'চেয়ে', 'তিনি', 'দিয়ে', 'তাহলে', 'হৈলে', 'থেকেই', 'সেটাই', 'প্রযন্ত', 'পর', 'নেওয়ার', 'তবু', 'নিজেদের', 'জানানো', 'যখন', 'বাদে', 'পরেও', 'এবং', 'আপনার', 'থাকে', 'ঠিক', 'মোটেই', 'এটাই', 'ইহা', 'কিন্তু', 'ধরা', 'সহ', 'এঁরা', 'বলে', 'বহু', 'আমাকে', 'ও', 'জন্যওজে', 'যেন', 'হলেই', 'দিয়েছে', 'উচিত', 'তাহা', 'এটা', 'কত', 'কারও', 'অতএব', 'সেটি', 'এরা', 'ফিরে', 'আছে', 'ছাড়া', 'জানিয়ে', 'করলে', 'প্রতি', 'কখনও', 'থাকায়', 'গিয়ে', 'হয়নি', 'জে', 'নয়', 'তার', 'রাখা', 'অনেকে', 'অথবা', 'জনের', 'থেকেও', 'যাঁরা', 'অন্তত', 'দিকে', 'থাকা', 'হতেই', 'কী', 'যেখানে', 'দেওয়া', 'খুব', 'কাজ', 'আরও', 'কোটি', 'ধরে', 'হাজার', 'সেখান', 'এস', 'করার', 'তাহার', 'পারে', 'বলল', 'মধ্যে', 'স্বয়ং', 'হওয়ায়', 'কেউই', 'দিন', 'যাঁর', 'সঙ্গে', 'চলে', 'মাত্র', 'করেই', 'মধ্যভাগে', 'সমস্ত', 'ওকে', 'কাজে', 'কিংবা', 'বেশি', 'কেউ', 'পক্ষে', 'হয়েছেন', 'যদিও', 'চার', 'নতুন', 'এখন', 'বি', 'হয়তো', 'সেটাও', 'উপর', 'জানা', 'করছে', 'এতটাই', 'জন্য', 'যার', 'মনে', 'ওখানে', 'নাকি', 'গেছে', 'প্রায়', 'করতে', 'করবে', 'থাকবে', 'ওদের', 'তারপর', 'ওঁর', 'তিনিও', 'আজ', 'চালু', 'দিয়েছেন', 'নানা', 'হয়েই', 'আমরা', 'জানায়', 'তাঁকে', 'এই', 'মতো', 'দেওয়া', 'নিয়ে', 'পাচ', 'বলেছেন', 'হয়ে', 'তা', 'অন্য', 'নিতে', 'কোন', 'এবার', 'সঙ্গেও', 'নিজেই', 'আগে', 'ছিল', 'প্রাথমিক', 'জনকে', 'যাবে', 'নিজে', 'জ্নজন', 'করিতে', 'এ', 'করেছেন', 'থাকবেন', 'না', 'হয়', 'এর', 'তারৈ', 'কয়েকটি', 'দুই', 'কাছ', 'তাঁরা', 'করলেন', 'এব', 'প্রায়', 'যেতে', 'মতোই', 'এত', 'ছাড়াও', 'ইত্যাদি', 'স্পষ্ট', 'হতে', 'পি', 'কেন', 'কিছু', 'মধ্যেই', 'দেখতে', 'হওয়ার', 'উত্তর', 'আমি', 'সহিত', 'করি', 'অনেক', 'আগেই', 'করাই', 'এখানে', 'কাউকে', 'যিনি', 'অনুযায়ী', 'চায়', 'সেখানে', 'ওরা', 'বা', 'দু', 'বদলে', 'গেল', 'রয়েছে', 'বসে', 'দেন', 'আর', 'অথচ', 'তাকে', 'গেলে', 'লক্ষ', 'যাকে', 'তিনঐ', 'মাধ্যমে', 'তাই', 'পরেই', 'তেমন', 'কোনও', 'কেখা', 'বরং', 'বিশেষ', 'হইতে', 'অবশ্য', 'কয়েক', 'জন', 'অর্থাত', 'নেওয়া', 'তাতে', 'শুধু', 'বন', 'করেন', 'করিয়া', 'কিছুই', 'শুরু', 'ওই', 'কমনে', 'যাওয়ার', 'পর্যন্ত', 'গিয়েছে', 'যাচ্ছে', 'চান', 'দুটি', 'সেই', 'পাওয়া', 'উপরে', 'প্রভৃতি', 'ক্ষেত্রে', 'রকম', 'সে', 'হয়েছিল', 'যে', 'টি', 'তাহাতে', 'ছিলেন', 'সি', 'আগামী', 'ফের', 'যদি', 'করায়', 'তাঁাহারা', 'তাদের', 'ব্যবহার', 'বিষয়টি'] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "bn_stop_words = list(stopwords.stopwords(\"bn\"))  # English stopwords\n",
    "print(len(bn_stop_words))\n",
    "print(bn_stop_words, type(bn_stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "x, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name):\n",
    "    global total, x, y\n",
    "    print(\"total = \", total)\n",
    "    csv_file = open(file_name, 'r', encoding='utf-8', errors='ignore')\n",
    "    csv_lines = csv.reader(csv_file, delimiter=\"\\t\")\n",
    "    ct = 0\n",
    "    for row in csv_lines:\n",
    "        ct = ct + 1\n",
    "        if ct == 1:\n",
    "            continue\n",
    "        try:\n",
    "            text = row[1].strip()\n",
    "            class_label = row[2].strip()\n",
    "            x.append(text)\n",
    "            y.append(class_label)\n",
    "            total = total + 1\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "            # print(row)\n",
    "    print(\"done\")\n",
    "    print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['multichannel_bsentiment_train.tsv', '.DS_Store', 'multichannel_bsentiment_test.tsv', 'multichannel_bsentiment_dev.tsv']\n",
      "multichannel_bsentiment_train.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/multichannel_bsentiment/multichannel_bsentiment_train.tsv\n",
      "total =  0\n",
      "done\n",
      "5510\n",
      ".DS_Store\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/multichannel_bsentiment/.DS_Store\n",
      "total =  5510\n",
      "line contains NULL byte\n",
      "multichannel_bsentiment_test.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/multichannel_bsentiment/multichannel_bsentiment_test.tsv\n",
      "total =  5510\n",
      "done\n",
      "7042\n",
      "multichannel_bsentiment_dev.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/multichannel_bsentiment/multichannel_bsentiment_dev.tsv\n",
      "total =  7042\n",
      "done\n",
      "8420\n",
      "['BN_data_dev.csv', 'BN_data_train.csv', 'BN_data_test.csv']\n",
      "BN_data_dev.csv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/SAIL_data/BN_data_dev.csv\n",
      "total =  8420\n",
      "done\n",
      "8518\n",
      "BN_data_train.csv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/SAIL_data/BN_data_train.csv\n",
      "total =  8518\n",
      "done\n",
      "9215\n",
      "BN_data_test.csv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/SAIL_data/BN_data_test.csv\n",
      "total =  9215\n",
      "done\n",
      "9419\n",
      "['sentiment_dev.tsv', 'sentiment_train.tsv', 'sentiment_test.tsv']\n",
      "sentiment_dev.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/youtube_sentiment/sentiment_dev.tsv\n",
      "total =  9419\n",
      "done\n",
      "9838\n",
      "sentiment_train.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/youtube_sentiment/sentiment_train.tsv\n",
      "total =  9838\n",
      "done\n",
      "11795\n",
      "sentiment_test.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/youtube_sentiment/sentiment_test.tsv\n",
      "total =  11795\n",
      "done\n",
      "12215\n",
      "['BASA_restaurant_dev.tsv', 'BASA_cricket_train.tsv', 'BASA_cricket_test.tsv', 'BASA_cricket_dev.tsv', 'BASA_restaurant_train.tsv', 'BASA_restaurant_test.tsv']\n",
      "BASA_restaurant_dev.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_restaurant_dev.tsv\n",
      "total =  12215\n",
      "done\n",
      "12439\n",
      "BASA_cricket_train.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_cricket_train.tsv\n",
      "total =  12439\n",
      "done\n",
      "14524\n",
      "BASA_cricket_test.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_cricket_test.tsv\n",
      "total =  14524\n",
      "done\n",
      "14904\n",
      "BASA_cricket_dev.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_cricket_dev.tsv\n",
      "total =  14904\n",
      "done\n",
      "15276\n",
      "BASA_restaurant_train.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_restaurant_train.tsv\n",
      "total =  15276\n",
      "done\n",
      "16641\n",
      "BASA_restaurant_test.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/ABSA_Datasets/BASA_restaurant_test.tsv\n",
      "total =  16641\n",
      "done\n",
      "16860\n",
      "['bn_all_dev.tsv', 'bn_all_test.tsv', 'bn_all_train.tsv']\n",
      "bn_all_dev.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/consolidated/bn_all_dev.tsv\n",
      "total =  16860\n",
      "done\n",
      "20246\n",
      "bn_all_test.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/consolidated/bn_all_test.tsv\n",
      "total =  20246\n",
      "done\n",
      "23800\n",
      "bn_all_train.tsv\n",
      "/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data/consolidated/bn_all_train.tsv\n",
      "total =  23800\n",
      "done\n",
      "39376\n"
     ]
    }
   ],
   "source": [
    "# dataset prepare\n",
    "path = '/home/tiger/Desktop/Others/bn_sentiment_analysis/bn-sentiment-analysis/bangla-sentiment-classification/data'\n",
    "folders = os.listdir(path)\n",
    "for fold in folders:\n",
    "    sub_path = os.path.join(path, fold)\n",
    "    try:\n",
    "        files_sub_path = os.listdir(sub_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    print(files_sub_path)\n",
    "    for f in files_sub_path:\n",
    "        print(f)\n",
    "        try:\n",
    "            data_file = os.path.join(sub_path, f)\n",
    "            print(data_file)\n",
    "            read_csv(file_name=data_file)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39376 39376\n"
     ]
    }
   ],
   "source": [
    "print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_entity():\n",
    "    global x\n",
    "    _dict_words, _dict_chars = {}, {}  \n",
    "    un_char, un_word = 0, 0\n",
    "    for i in range(0, len(x)):\n",
    "        x_t = x[i].strip().split(' ')\n",
    "        for j in range(0, len(x_t)):\n",
    "            if _dict_words.get(x_t[j]) is None:\n",
    "                _dict_words[x_t[j]] = un_word\n",
    "                un_word = un_word + 1\n",
    "                for k in range(0, len(x_t[j])):\n",
    "                    if _dict_chars.get(x_t[j][k]) is None:\n",
    "                        _dict_chars[x_t[j][k]] = un_char\n",
    "                        un_char = un_char + 1\n",
    "    _dict_chars[' '] = un_char\n",
    "    un_char = un_char + 1\n",
    "    _dict_chars['UNK'] = un_char\n",
    "    un_char = un_char + 1\n",
    "    _dict_words['UNK'] = un_word\n",
    "    un_word = un_word + 1\n",
    "    return _dict_words, _dict_chars, un_word, un_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dict_words, _dict_chars, un_word, un_char = find_unique_entity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58250 447\n",
      "আল্লাহ\n",
      "অবশ্যই\n",
      "এদের\n",
      "পাশে\n",
      "থাকবে।\n",
      "বেগম\n",
      "খালেদা\n",
      "জিয়া\n",
      "সঠিক\n",
      "বলেছেন।\n"
     ]
    }
   ],
   "source": [
    "print(un_word, un_char)\n",
    "cnt = 0\n",
    "for key in _dict_words:\n",
    "    print(key)\n",
    "    cnt = cnt + 1\n",
    "    if cnt >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(text, _dict):\n",
    "    _list = []\n",
    "    for i in text:\n",
    "        if _dict.get(i) is not None:\n",
    "            _list.append(_dict.get(i))\n",
    "        else:\n",
    "            _list.append(_dict.get('UNK'))\n",
    "    return torch.tensor(_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,  19,  22, 445,  28,   3,  29, 445,  20,   3,   9])\n"
     ]
    }
   ],
   "source": [
    "ten = convert_to_tensor(text='আমি ভাত খাই', _dict=_dict_chars)\n",
    "print(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_split(x):\n",
    "    x_sp = []\n",
    "    for i in range(0, len(x)):\n",
    "        x_sp.append(x[i].strip().split(' '))\n",
    "    return x_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_split(x):\n",
    "    x_sp = []\n",
    "    for i in range(0, len(x)):\n",
    "        x_sp.append([])\n",
    "        for j in range(0, len(x[i])):\n",
    "            x_sp[-1].append(x[i][j])\n",
    "    return x_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_label_tensor(label, length):\n",
    "    class_labels = {'Positive':0, 'Negative': 1, 'Neutral':2, 'CHAR': 3}\n",
    "    _list = []\n",
    "    for i in range(0, length):\n",
    "        _list.append(3)\n",
    "    _list[-1] = class_labels.get(label)\n",
    "    return torch.tensor(_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sp = word_split(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sp = character_split(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=x_sp, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8d01a3059e82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/tiger/.local/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tiger/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tiger/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
      "\u001b[0;32m/home/tiger/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    486\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tiger/.local/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(x_sp, total_examples=len(x_sp), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0519831   0.41506708  0.5715881   0.15478212 -0.8437905  -0.62667423\n",
      " -1.0708227   1.1914564  -0.42528915 -0.15674004  0.7707798   0.18152404\n",
      "  0.7265559  -0.67547137 -0.1547602  -0.05224869  0.8142949  -0.12199134\n",
      "  1.689111   -0.08687642  0.3661721   1.2441468   0.78058094  1.2952548\n",
      "  1.2217561   1.1133622   1.5494412  -0.37127477 -0.11423025 -1.8716185\n",
      "  0.3275369  -0.2696631   1.5278866   0.00556274 -1.0404832  -1.4043034\n",
      "  1.7013118  -1.6717616  -1.2209673   2.1107757  -0.66324216  1.2598041\n",
      "  0.6109308   0.39171836  0.17907815 -1.3827776   0.13344991  0.9439052\n",
      " -0.2413157   0.774605   -0.04348729 -0.37464482  0.9169178   1.10394\n",
      "  0.3490382  -0.4019057   0.03289803  0.7969891  -0.06541738  0.5553017\n",
      "  0.75347227  0.57617074 -1.5448701  -0.7368425   1.8713099   0.28087717\n",
      " -0.48923835  0.4230941   0.37347713 -1.1546379  -3.015154    0.8593498\n",
      "  0.06480893  0.37680912 -1.2456199  -0.23922507 -0.71932566 -0.37288252\n",
      " -0.28084898  1.1190468  -0.31345597  0.9177346  -0.33056906 -0.14611326\n",
      "  0.6726971  -0.3546866   1.9281251  -0.17953213 -0.8617985  -0.91471106\n",
      "  0.6600104   0.05348365 -0.08670768  0.58575094 -0.20475362  1.0266886\n",
      " -0.4426917  -0.3073287  -0.8926158   0.30350295]\n",
      "(100,)\n",
      "[('প', 0.6580386161804199)]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv['ক']  # get numpy vector of a word\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "sims = model.wv.most_similar('ক', topn=1)  # get other similar words\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentence):\n",
    "    global model\n",
    "    embedding = []\n",
    "    for i in range(0, len(sentence)):\n",
    "        if  word2vec.wv.vocab.get(sentence[i]) is not None:\n",
    "            vector = word2vec.wv[sentence[i]]  # get numpy vector of a word\n",
    "        else:\n",
    "            vector = word2vec.wv['UNK']\n",
    "        embedding.append(vector)\n",
    "    return torch.tensor(embedding, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTSentimentAnalysis(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super(LSTMTSentimentAnalysis, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = get_embeddings(sentence=sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5254, -0.6268,  0.4237,  ...,  0.8656, -0.0869, -0.6897]],\n",
      "\n",
      "        [[ 0.7697, -0.1915,  0.4888,  ..., -1.6165, -0.0739,  0.1430]],\n",
      "\n",
      "        [[ 0.1323,  0.2862,  1.3052,  ..., -1.3091,  0.1415,  1.1300]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0347,  0.0448,  1.2166,  ...,  0.4497, -0.5181, -0.1260]],\n",
      "\n",
      "        [[ 0.4815, -1.1033,  1.0673,  ..., -0.4978,  0.8795,  0.1726]],\n",
      "\n",
      "        [[ 0.8123,  0.5064,  1.7163,  ..., -0.0282,  0.1577,  1.1815]]])\n"
     ]
    }
   ],
   "source": [
    "sentence = 'আমি ভাত খাই'\n",
    "embeds = get_embeddings(sentence=sentence)\n",
    "embeds = embeds.view(len(sentence), 1, -1)\n",
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTSentimentAnalysis(embedding_dim=100, hidden_dim=100, vocab_size=un_char, target_size=4)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "torch.Size([30])\n",
      "torch.Size([30, 4])\n",
      "tensor([-1.2118, -1.4925, -1.3233, -1.5547])\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 0])\n",
      "tensor(1.4615)\n"
     ]
    }
   ],
   "source": [
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    scores = model(x[0])\n",
    "    print(y[0])\n",
    "    targets = class_label_tensor(label=y[0], length=len(x[0]))\n",
    "    print(targets.shape)\n",
    "    print(scores.shape)\n",
    "print(scores[-1])\n",
    "print(targets)\n",
    "loss = loss_function(scores, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional information\n",
    "def save_checkpoint(epoch, path, loss, net, optimizer):\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, _train=True):\n",
    "    model = LSTMTSentimentAnalysis(embedding_dim=100, hidden_dim=100, vocab_size=un_char, target_size=4)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    if _train is True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    return model, loss_function, optimizer, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "0 tensor(0.0217, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model, loss_function, optimizer, curr_epoch, curr_loss = load_checkpoint(path='model.pt', _train=True)\n",
    "print(\"loaded\")\n",
    "print(curr_epoch, curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial\n",
    "curr_epoch = 0\n",
    "curr_loss = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 1\n",
    "for epoch in range(itr):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    curr_epoch = curr_epoch + 1\n",
    "    for i in range(0, len(x)):\n",
    "        if y[i] not in ['Positive', 'Negative', 'Neutral']:\n",
    "            continue\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        targets = class_label_tensor(label=y[i], length=len(x[i]))\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        scores = model(x[i])\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0101, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)\n",
    "if loss < curr_loss:\n",
    "    curr_loss = loss\n",
    "    save_checkpoint(curr_epoch, 'model.pt', curr_loss, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "8 tensor(0.0101, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model, loss_function, optimizer, curr_epoch, curr_loss = load_checkpoint(path='model.pt', _train=False)\n",
    "print(\"loaded\")\n",
    "print(curr_epoch, curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sentence):\n",
    "    scores = model(sentence)\n",
    "    last_one = scores[-1]\n",
    "    last_one = last_one.cpu().detach().numpy()\n",
    "    save = [[0.0,'POSITIVE'], [0.0,'NEGATIVE'], [0.0,'NEUTRAL'], [0.0,'CHAR']]\n",
    "    for i in range(0, len(last_one)):\n",
    "        save[i][0] = last_one[i]\n",
    "    save.sort(key=lambda x:x[0], reverse=True)\n",
    "    fn_score, fn_label = save[0][0], save[0][1]\n",
    "    if save[0][1] == 'CHAR':\n",
    "        fn_score, fn_label = save[1][0], save[1][1]\n",
    "    print(fn_score, fn_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.479175 POSITIVE\n",
      "-7.8314705 POSITIVE\n"
     ]
    }
   ],
   "source": [
    "test('তুমি ভাল ছেলে')\n",
    "test('তুমি খারাপ ছেলে')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
